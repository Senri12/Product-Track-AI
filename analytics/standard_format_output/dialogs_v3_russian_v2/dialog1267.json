{
  "metadata": {
    "dialog_id": "dialog1267",
    "model_name": "granite3.2",
    "model_parameters": "2.0B",
    "system_prompt_id": "prompt13",
    "lecture_title": "1_Классификаторы_KNN_и_наивный_байес",
    "lecture_topic": "Как вычислить вероятность класса в Naive Bayes?",
    "f1": 33.2,
    "precision": 32.1,
    "recall": 46.7,
    "claim_recall": 35.5,
    "context_precision": 50.0,
    "context_utilization": 33.4,
    "hallucination": 12.0,
    "faithfulness": 33.6,
    "noise_sensitivity": 19.6,
    "self_knowledge": 4.4,
    "timestamp": "2025-10-28T13:24:20.105321"
  },
  "turns": [
    {
      "turn_number": 1,
      "role": "user",
      "content": "Как вычислить вероятность класса в Naive Bayes?",
      "model_response": "",
      "rating": ""
    },
    {
      "turn_number": 2,
      "role": "assistant",
      "content": "",
      "model_response": "Когда объем тренировочных данных достаточно большой, чтобы предположение о независимости слов в тексте на одну и ту же тему почти сохранилось, вероятность класса (P(Класс = y)) может быть оценита частотой, а условные вероятности P(X_i|Класс = y) – также.\n\n1. **Оценка частот**: Преобразуйте текст в набор слов (word-level frequency), где каждое слово является единицей. Вычислите частотность каждого слова в предложении, а затем вычислите частотность всей матрицы слов в тексте.\n\n2. **Условные вероятности**: Применяйте формулу для условных вероятностей, используя частоты:\n\n   P(X_i|Класс = y) ≈ (Частота слова X_i в тексте к классу y) / (Частота всех слов в тексте к классу y)\n\n3. **Оценка вероятности класса**: Вычислите вероятность каждого класса Y как произведения частот этих слов в тексте на одну и ту же тему:\n\n   P(Класс = y) ≈ (Частота всех слов в тексте к классу y)\n\n4. **Оценка классификатора**: Используя вычисленные вероятности, вычислите результат классификатора:\n\n   $$y^\\ast = \\mathop{\\mathrm{Arg\\,max}}_{y \\in Y}\\left( P(\\text{Класс} = y) \\prod_{i=1}^{p} P\\left(X_i | \\text{Класс} = y\\right) \\right).$$\n\nВ этом выражении, `P(X₁|Класс = y)`, `P(X₂|Класс = y)` и т.д. – представляют условные вероятности слов по классу, а `P(Класс = y)` – частота каждого класса в тексте. Полученный значение `y^*` будет наиболее вероятным классом для нового предложения.\n\nВычисления частот и условные вероятности могут быть делены на большое количество, чтобы уменьшить эффект случайного перебора. Это называется «получение статистически значимого», которое считается выполняться когда частотные значения достигают определенного нижнего количества.",
      "rating": ""
    }
  ]
}