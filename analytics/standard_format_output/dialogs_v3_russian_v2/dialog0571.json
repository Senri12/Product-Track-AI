{
  "metadata": {
    "dialog_id": "dialog0571",
    "model_name": "mistral",
    "model_parameters": "7.0B",
    "system_prompt_id": "prompt5",
    "lecture_title": "1_Классификаторы_KNN_и_наивный_байес",
    "lecture_topic": "Что такое метод k-ближайших соседей?",
    "f1": 42.2,
    "precision": 39.5,
    "recall": 52.2,
    "claim_recall": 35.2,
    "context_precision": 50.0,
    "context_utilization": 33.0,
    "hallucination": 10.3,
    "faithfulness": 33.8,
    "noise_sensitivity": 18.5,
    "self_knowledge": 5.9,
    "timestamp": "2025-10-28T13:24:20.262255"
  },
  "turns": [
    {
      "turn_number": 1,
      "role": "user",
      "content": "Что такое метод k-ближайших соседей?",
      "model_response": "",
      "rating": ""
    },
    {
      "turn_number": 2,
      "role": "assistant",
      "content": "",
      "model_response": " Метод k-ближайших соседей (k-NN) - это статистический алгоритм классификации, который классифицирует новые данные по их сходству или расстоянию к тренировочным данным. Этот метод работает на основании того, что ближайшие к новому объекту обучающие примеры будут иметь большую вероятность принадлежать тому же классу. В алгоритме k-NN для каждого нового объекта выбирают к ближайших по расстоянию k тренировочных объектов (общим числом k-ближайших соседей), и классифицируют новый объект по большинству их классов. Если разные к-ближайших соседа имеют различные классы, то может быть использована стратегия проголосования (взвешенный k-NN) для выбора самого вероятного класса нового объекта. Для метрики к-ближайших соседей чаще всего используется евклидовское расстояние, но могут быть использованы и другие метрики (например, Манхэттенское расстояние).",
      "rating": ""
    }
  ]
}