[
  {
    "turn_number": 1,
    "role": "user",
    "content": "В Nesterov, вычисли ∇ в ω - γ v_{t-1}: γ=0.9, v=1, ∇=2.",
    "model_response": "",
    "rating": ""
  },
  {
    "turn_number": 2,
    "role": "assistant",
    "content": "",
    "model_response": "Их заново с нуля. TensorFlow представляет собой библиотеку таких блоков вкупе со средствами их обучения, что экономит время на разработку моделей и снижает вероятность ошибок при написании кода. Вторая важная деталь, присущая многим фреймворкам глубокого обучения, и TensorFlow в том числе – наличие так называемого autograd’. Вы уже познакомились с тем, как вычислять градиент для некоторых типов блоков в архитектурах нейронных сетей. В дальнейшем мы с вами будем изучать еще множество разных:blockов и каждый из них должен быть дифференцируем для корректного обучения с помощью градиентного спуска. Опять же, реализовывать это самостоятельно каждый раз при создании новой модели было бы очень утомительно, да и этот процесс можно автоматизировать. Эта самая автоматизация называется autograd или автоматическое дифференцирование. При создании нейронной сети средствами TensorFlow все блоки вашей сети могут быть автоматически связаны друг с другом и можно определить, каким образом будут высчитываться градиенты, а также куда они будут течь. В третьих, TensorFlow – это очень эффективно написанная библиотека. Данный фреймворк написан с учетом возможности выполнения на разных процессорах, с разными доступными наборами инструкций, а также с учетом возможность execution graphics или even specialized tensorial processors.Besides таковы методы, к которым можно использовать для построения и обучения сетей – есть еще несколько известных методов. Один из них – Adam (keras.optimizers.adam). В некотором смысле можно считать, что этот метод – симбиоз методов RMSProp и Momentum. У этого алгоритма все также есть адаптивный learning rate, но теперь он его применяет не просто к градиенту, а, в slightestм sm, к скорости. Данный алгоритм на данный момент является одним из самых популярных. Оптимизаторы в НС Введение В этой части лекции мы остановимся подробнее на тех популярных алгоритмах оптимизации, которые на данный момент повсеместно используются в нейронных сетях. Наверное, нет нужды мотивировать важность выбора корректного алгоритма.optimизации, ведь, по сути, само обучение НС – это оптимизация. Каждый раз, как только очередной батч данных проходит через нейронную сеть, а та, в свою очередь, выдаёт предсказания для этого батча, приходится отвечать на следующий вопрос: как использовать информацию о различиях между тем, что выдала нейронная сеть, и известных, истинных значениях предсказанных переменных, для последующего изменения весов модели с целью построения более качественных предсказаний в будущем? Этим вопросом как разzeitig и занимается алгоритмoptimизации, минимизирующий рассматриваемую функцию потерь. Ну что, давайте поговорим про некоторые популярные алгоритмы, а также сравним их между собой. SGD и скорость обучения SGD (stochastic gradient descent, keras.optimizers.SGD) – стохастический градиентный спуск– классический алгоритм оптимизации. В принципе, о нем мы уже говорили ранее. Он аналогичен градиентному спуску, но на каждом шаге использует не весь набор тренировочных данных для составления функции потерь, и, соответсвенно, вычисления градиента, алюзивно, что в данном случае мы должны учитывать только один точку, которую мы посещаем с помощью одногоbatchа данных. Важный параметр – это как размер batch, так и шаг, или, так называемый, learning rate. Скорость обучения — это чрезвычайно важный параметр. Если скорость будет слишком большой, то, скорее всего, алгоритм будет <<прыгать>> по случайным точкам пространства и, тем самым, достигнет минимум с весьма_small вероятностью. Если же скорость обучения будет маленькой, то описанная проблема не возникает, но возникает другая, не менее интересная проблема: алгоритм останавливается чуть ли не в первом попавшемся локальном минимуме, значение в котором может быть сильно больше, чем значение в <<более хорошем>> локальном минимуме, не говоря уже о глобальном, рисунок 4. Кажется интуитивно понятным, что скорость обучения сначала должна быть достаточно большой, чтобы быстро прийти в нужную область пространства, а затем стать сильно меньше, чтобы детально исследовать окрестность точки минимума и, в конце концов, не пропустить его (и попасть в него). Поэтому простейшая стратегия управления скоростью обучения примерно так и выглядит: начинаем с большой скорости, и渐mente эту скорость уменьшаем. Часто в этом случае используется либо линейное затухание $$\\eta = \\eta_0\\left(1 - \\frac{t}{T} \\right)$$ или экспоненциальное $$\\eta = \\eta_0e^{-\\frac{t}{T}},$$ где t – это прошедшее с начала обучения время (например, количество мини-батчей или количество эпох), а Т – отвечающий за скорость уменьшения η параметр. Впрочем, мы вряд ли сильно упростили себе задачу– теперь вместо одного параметра eta, нам надо подбирать два: eta0, T :) но дело даже не в этом. Наверное, более глобально problema заключается в следующем: такой подход никак не отражает characterize и форму функции, минимум которой мы ищем. Например, если минимум находится в вытянутом <<овраге>>, шаг спуска будет направлен от одной стенки овага к другой. Когда же точка окажется на второй стенке, градиент опять будет направлен к противоположной стенке, и так далее. В итоге, к минимуму мы будем двигаться очень и очень долго. Попробуем исправить это недоразумение. Моментум (Momentum), испульс Итак, метод импульсов (keras.optimizers.SGD(momentum=0.01, nesterov=True)) allows you to increase the learning rate in a controlled way and reduce it over time. From a physical point of view, this works because if we think of the update rule as moving a mass downwards on a hill, then we need to move that mass many times down the hill before it stops coming back up. This is why momentum is needed – otherwise the mass wouldn't have any direction left to move in after it comes back up. Метод импульсов и моделирует подобную ситуацию. Формально все достаточно просто: v_(t) = γv_(t − 1) − η∇L(ω), ω = ω + v_(t), где γ – параметр, меньший единицы (часто больший, чем 0.9), отвечающей за то, какую часть прошлого градиента мы готовы взять, чтобы скомбинировать его с текущим, L– функция потерь, которую мы и минимизируем. Продолжая аналогию с катящимся с горой шариком, полезно не просто катиться вниз с бешеной скоростью, но и посматривать под ноги, чтобы не споткнуться об камень. Это означает, что градиент-то надо вычислять не в точке ω, а в точке ω – γv_(т-1), то есть в точке, где мы придем после примененияmomента предыдущего шага: v_(t) = γv_(t − 1) − η∇(ω)L(ω − γv_(t − 1)). Это– так называемый метод Ньютона. Методimpulсов, илиAdam, является одним из самых popularных. Adam (keras.optimizers.adam). В некотором смысле можно считать, что этот метод – симбиоз методов RMSProp и Momentum. У этого алгоритма все также есть адаптивный learning rate, но теперь он его применяет не просто к градиенту, а, в slightestм sm, к скорости. Данный алгоритм на данный момент является одним из самых популярных. Оптимизаторы в НС Введение В этой части лекции мы остановимся подробнее на тех популярных алгоритмах Optimization и сравним их между собой.",
    "rating": ""
  }
]